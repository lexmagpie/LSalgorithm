{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import normalvariate\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BGM(curve0):\n",
    "    curve_run = curve0.copy()\n",
    "    curve = [curve0.copy()]\n",
    "    for t in range(0, 4):\n",
    "        y = normalvariate(0,1)\n",
    "        for i in range(len(curve_run)-1, t, -1):\n",
    "            A = volY**2*sum( [e/(1+e) for e in curve_run[t+1:i+1]] )\n",
    "            curve_run[i] *= np.exp((A-volY**2/2)+volY*y)\n",
    "            i+=1\n",
    "        curve += [curve_run.copy()]\n",
    "        t += 1\n",
    "    \n",
    "    return curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bond(ti, curve):\n",
    "    df = np.zeros(T)\n",
    "    b = 0\n",
    "    for i in range(0, T-ti):\n",
    "        df[ti+i] = 1/(1+curve[ti+i])\n",
    "        DF = np.prod(df[ti:ti+1+i])\n",
    "        b += C[ti+i]*N*DF\n",
    "        i += 1\n",
    "        \n",
    "    b += N*np.prod(df[ti:])\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC(n, curve0):\n",
    "    bonds = []\n",
    "    rates = []\n",
    "    for i in range(n):\n",
    "        new_curve = BGM(curve0)\n",
    "        rates += [[0]+new_curve[4]]\n",
    "        bonds += [[bond(0, new_curve[0]),\n",
    "                   bond(1, new_curve[1]),\n",
    "                   bond(2, new_curve[2]),\n",
    "                   bond(3, new_curve[3]),\n",
    "                   bond(4, new_curve[4])]]\n",
    "    \n",
    "    dfs = 1/(1+np.array(rates))\n",
    "    return np.array(bonds).T, np.array(rates).T, np.array(dfs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 # notional\n",
    "T = 5 # number of years in total\n",
    "volY = 0.10 # volatility of the zero curve\n",
    "K = 101 # strike price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10**6 # number of MC simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contango => evenly distributed among exercise dates\n",
    "C = [0.03, 0.04, 0.05, 0.06, 0.06] # coupons\n",
    "y_curve = [0.029, 0.036, 0.041, 0.044, 0.045] # zero curve w/ discrete compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The forward curve derived from the zero curve given: [0.029 0.043 0.051 0.053 0.049]\n"
     ]
    }
   ],
   "source": [
    "curve0 = [y_curve[0]] + [ ( (1+y_curve[i+1])**(i+2) / (1+y_curve[i])**(i+1) )**(1/((i+2)-(i+1))) -1 for i in range(len(y_curve)-1)]\n",
    "print('The forward curve derived from the zero curve given:', np.around(curve0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = MC(n, curve0)\n",
    "paths, rates, dfs= mc[0], mc[1], mc[2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "paths0, rates0, dfs0 = paths.copy(), rates.copy(), dfs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = int(n*0.5)\n",
    "rates_is, rates_oos = paths.T[:a].T, paths.T[a:].T\n",
    "paths_is, paths_oos = paths.T[:a].T, paths.T[a:].T\n",
    "dfs_is, dfs_oos = dfs.T[:a].T, dfs.T[a:].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IN SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, rates, dfs = paths_is, rates_is, dfs_is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YEAR 4\n",
    "\n",
    "V = np.zeros(shape=(T,a))\n",
    "V[4] = np.where(paths[4]>K, paths[4]-K, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YEAR 3\n",
    "\n",
    "# making an array of indices of the paths where in year 3 S (ITM) > K\n",
    "ind_itm_3y = np.where(paths[3]>K)[0]\n",
    "\n",
    "# selecting S in year 3 where S (ITM) > K\n",
    "S_3y = paths[3][ind_itm_3y]\n",
    "\n",
    "# selecting exercise values in year 3\n",
    "exercise_V_3y = S_3y - K\n",
    "\n",
    "#discounting to year 3 the cash flows in year 4 where S > K\n",
    "disc_V_3y = V[4][ind_itm_3y]*dfs[4][ind_itm_3y]\n",
    "\n",
    "# obtaining values of continuing at year 3\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(S_3y.reshape(-1, 1))  \n",
    "S_3y_scld = scaler.transform(S_3y.reshape(-1, 1))\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(3, 10), activation = 'relu', # hidden_layer_sizes = (# hidden layers, # neurons in each layer)\n",
    "                   solver='adam', max_iter=200, alpha=1e-5) # epochs = # max_iter\n",
    "fitted3 = mlp.fit(S_3y_scld.reshape(-1, 1), disc_V_3y)\n",
    "continuation_V_3y = fitted3.predict(S_3y_scld.reshape(-1, 1))\n",
    "\n",
    "# selecting indices of original paths where exercise_V_3y > continuation_V_3y\n",
    "ind_3y = np.take(ind_itm_3y, np.where(exercise_V_3y > continuation_V_3y))[0]\n",
    "\n",
    "# inserting exercise values in cash flows in year 3 where exercise_V_3y > continuation_V_3y\n",
    "V[3][ind_3y] = exercise_V_3y[np.where(exercise_V_3y > continuation_V_3y)]\n",
    "\n",
    "# inserting zero values in cash flows in year 4 where exercise_V_3y > continuation_V_3y\n",
    "V[4][ind_3y] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YEAR 2\n",
    "\n",
    "# making an array of indices of the paths where in year 2 S (ITM) > K\n",
    "ind_itm_2y = np.where(paths[2]>K)[0]\n",
    "\n",
    "# selecting S in year 2 where S (ITM) > K\n",
    "S_2y = paths[2][ind_itm_2y]\n",
    "\n",
    "# selecting exercise values in year 2\n",
    "exercise_V_2y = S_2y - K\n",
    "\n",
    "# discounting to year 2 the cash flows of year 3 where S > K and the cash flows of year 4 where S > K\n",
    "disc_V_2y =  np.maximum(V[3][ind_itm_2y]*dfs[3][ind_itm_2y],\n",
    "                        V[4][ind_itm_2y]*dfs[3][ind_itm_2y]*dfs[4][ind_itm_2y])\n",
    "\n",
    "# obtaining values of continuing in year 2\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(S_2y.reshape(-1, 1))  \n",
    "S_2y_scld = scaler.transform(S_2y.reshape(-1, 1))\n",
    "fitted2 = mlp.fit(S_2y_scld.reshape(-1, 1), disc_V_2y)\n",
    "continuation_V_2y = fitted2.predict(S_2y_scld.reshape(-1, 1))\n",
    "\n",
    "# selecting indices of original paths where exercise_V_2y > continuation_V_2y\n",
    "ind_2y = np.take(ind_itm_2y, np.where(exercise_V_2y > continuation_V_2y))[0]\n",
    "\n",
    "# inserting exercise values in cash flows in year 2 where exercise_V_2y > continuation_V_2y\n",
    "V[2][ind_2y] = exercise_V_2y[np.where(exercise_V_2y > continuation_V_2y)]\n",
    "\n",
    "# inserting zero values in cash flows in year 3 and year 4 where exercise_V_2y > continuation_V_2y\n",
    "V[3][ind_2y], V[4][ind_2y] = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YEAR 1\n",
    "\n",
    "# making an array of indices of the paths where in year 1 S (ITM) > K\n",
    "ind_itm_1y = np.where(paths[1] > K)[0]\n",
    "\n",
    "# selecting S in year 1 where S (ITM) > K\n",
    "S_1y = paths[1][ind_itm_1y]\n",
    "\n",
    "# selecting exercise values in year 1\n",
    "exercise_V_1y = S_1y - K\n",
    "\n",
    "# discounting to year 1 the cash flows of year 2 where K > S and the cash flows of year 3 where K > S\n",
    "disc_V_1y =  np.maximum(V[2][ind_itm_1y]*dfs[2][ind_itm_1y],\n",
    "                        V[3][ind_itm_1y]*dfs[2][ind_itm_1y]*dfs[3][ind_itm_1y],\n",
    "                        V[4][ind_itm_1y]*dfs[2][ind_itm_1y]*dfs[3][ind_itm_1y]*dfs[4][ind_itm_1y])\n",
    "\n",
    "# obtaining values of continuing in year 2\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(S_1y.reshape(-1, 1))  \n",
    "S_1y_scld = scaler.transform(S_1y.reshape(-1, 1))\n",
    "fitted1 = mlp.fit(S_1y_scld.reshape(-1, 1), disc_V_1y)\n",
    "continuation_V_1y = fitted1.predict(S_1y_scld.reshape(-1, 1))\n",
    "\n",
    "# selecting indices of original paths where exercise_V_1y > continuation_V_1y\n",
    "ind_1y = np.take(ind_itm_1y, np.where(exercise_V_1y > continuation_V_1y))[0]\n",
    "\n",
    "# inserting exercise values in cash flows in year 1 where exercise_V_1y > continuation_V_1y\n",
    "V[1][ind_1y] = exercise_V_1y[np.where(exercise_V_1y > continuation_V_1y)]\n",
    "\n",
    "# inserting zero values in cash flows in year 2 and year 3 where exercise_V_1y > continuation_V_1y\n",
    "V[2][ind_1y], V[3][ind_1y], V[4][ind_1y] = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of call options: 500,000 \n",
      "\n",
      "t = 4: % ITM call options = 3.33% \n",
      "t = 4: % OTM call options = 96.67% \n",
      "\n",
      "t = 3: % ITM call options = 127.76% \n",
      "t = 3: % OTM call options = 72.24% \n",
      "\n",
      "t = 2: % ITM call options = 12.82% \n",
      "t = 2: % OTM call options = 74.36% \n",
      "\n",
      "t = 1: % ITM call options = 7.30% \n",
      "t = 1: % OTM call options = 85.41%\n"
     ]
    }
   ],
   "source": [
    "print(f'# of call options: {a:,.0f} \\n\\n' \\\n",
    "      f't = 4: % ITM call options = {(a-V[4][V[4]==0].shape[0])/a*100:,.2f}% \\n' \\\n",
    "      f't = 4: % OTM call options = {V[4][V[4]==0].shape[0]/a*100:,.2f}% \\n\\n' \\\n",
    "      f't = 3: % ITM call options = {(n-V[3][V[3]==0].shape[0])/a*100:,.2f}% \\n' \\\n",
    "      f't = 3: % OTM call options = {V[3][V[3]==0].shape[0]/a*100:,.2f}% \\n\\n' \\\n",
    "      f't = 2: % ITM call options = {(a-V[2][V[2]==0].shape[0])/n*100:,.2f}% \\n' \\\n",
    "      f't = 2: % OTM call options = {V[2][V[2]==0].shape[0]/a*100:,.2f}% \\n\\n' \\\n",
    "      f't = 1: % ITM call options = {(a-V[1][V[1]==0].shape[0])/n*100:,.2f}% \\n' \\\n",
    "      f't = 1: % OTM call options = {V[1][V[1]==0].shape[0]/a*100:,.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discounting values to year 0\n",
    "dfs_cum = np.array([np.cumprod(i) for i in dfs[1:].T]).T\n",
    "disc_V = V.copy()*dfs_cum\n",
    "\n",
    "# calculating the price and standard error\n",
    "c = np.sum([max(i) for i in disc_V.T])/a\n",
    "c2 = np.sum([max(i)**2 for i in disc_V.T])/a\n",
    "std_err = np.sqrt((c2-c**2)/a)\n",
    "call_bond = bond(0,curve0)-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bermudan call option price is: 1.1134512752. The standard error is: 0.0015247852. \n",
      "The bond price at t=0: 101.1849579254. The callable bond price at t=0: 100.0715066502.\n"
     ]
    }
   ],
   "source": [
    "print(f'The Bermudan call option price is: {c:.10f}. The standard error is: {std_err:.10f}. \\n' \\\n",
    "      f'The bond price at t=0: {bond(0,curve0):.10f}. The callable bond price at t=0: {call_bond:.10f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = [max(i) for i in disc_V.T]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OUT OF SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, rates, dfs = paths_oos, rates_oos, dfs_oos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YEAR 4\n",
    "\n",
    "V = np.zeros(shape=(T,n-a))\n",
    "V[4] = np.where(paths[4]>K, paths[4]-K, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YEAR 3\n",
    "\n",
    "# making an array of indices of the paths where in year 3 S (ITM) > K\n",
    "ind_itm_3y = np.where(paths[3]>K)[0]\n",
    "\n",
    "# selecting S in year 3 where S (ITM) > K\n",
    "S_3y = paths[3][ind_itm_3y]\n",
    "\n",
    "# selecting exercise values in year 3\n",
    "exercise_V_3y = S_3y - K\n",
    "\n",
    "#discounting to year 3 the cash flows in year 4 where S > K\n",
    "disc_V_3y = V[4][ind_itm_3y]*dfs[4][ind_itm_3y]\n",
    "\n",
    "# obtaining values of continuing at year 3\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(S_3y.reshape(-1, 1))  \n",
    "S_3y_scld = scaler.transform(S_3y.reshape(-1, 1))\n",
    "#mlp = MLPRegressor(hidden_layer_sizes=(3, 10), activation = 'relu', # hidden_layer_sizes = (# hidden layers, # neurons in each layer)\n",
    "                   #solver='adam', max_iter=200, alpha=1e-5) # epochs = # max_iter\n",
    "#mlp.fit(S_3y_scld.reshape(-1, 1), disc_V_3y)\n",
    "continuation_V_3y = fitted3.predict(S_3y_scld.reshape(-1, 1))\n",
    "\n",
    "# selecting indices of original paths where exercise_V_3y > continuation_V_3y\n",
    "ind_3y = np.take(ind_itm_3y, np.where(exercise_V_3y > continuation_V_3y))[0]\n",
    "\n",
    "# inserting exercise values in cash flows in year 3 where exercise_V_3y > continuation_V_3y\n",
    "V[3][ind_3y] = exercise_V_3y[np.where(exercise_V_3y > continuation_V_3y)]\n",
    "\n",
    "# inserting zero values in cash flows in year 4 where exercise_V_3y > continuation_V_3y\n",
    "V[4][ind_3y] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YEAR 2\n",
    "\n",
    "# making an array of indices of the paths where in year 2 S (ITM) > K\n",
    "ind_itm_2y = np.where(paths[2]>K)[0]\n",
    "\n",
    "# selecting S in year 2 where S (ITM) > K\n",
    "S_2y = paths[2][ind_itm_2y]\n",
    "\n",
    "# selecting exercise values in year 2\n",
    "exercise_V_2y = S_2y - K\n",
    "\n",
    "# discounting to year 2 the cash flows of year 3 where S > K and the cash flows of year 4 where S > K\n",
    "disc_V_2y =  np.maximum(V[3][ind_itm_2y]*dfs[3][ind_itm_2y],\n",
    "                        V[4][ind_itm_2y]*dfs[3][ind_itm_2y]*dfs[4][ind_itm_2y])\n",
    "\n",
    "# obtaining values of continuing in year 2\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(S_2y.reshape(-1, 1))  \n",
    "S_2y_scld = scaler.transform(S_2y.reshape(-1, 1))\n",
    "#mlp.fit(S_2y_scld.reshape(-1, 1), disc_V_2y)\n",
    "continuation_V_2y = fitted2.predict(S_2y_scld.reshape(-1, 1))\n",
    "\n",
    "# selecting indices of original paths where exercise_V_2y > continuation_V_2y\n",
    "ind_2y = np.take(ind_itm_2y, np.where(exercise_V_2y > continuation_V_2y))[0]\n",
    "\n",
    "# inserting exercise values in cash flows in year 2 where exercise_V_2y > continuation_V_2y\n",
    "V[2][ind_2y] = exercise_V_2y[np.where(exercise_V_2y > continuation_V_2y)]\n",
    "\n",
    "# inserting zero values in cash flows in year 3 and year 4 where exercise_V_2y > continuation_V_2y\n",
    "V[3][ind_2y], V[4][ind_2y] = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YEAR 1\n",
    "\n",
    "# making an array of indices of the paths where in year 1 S (ITM) > K\n",
    "ind_itm_1y = np.where(paths[1] > K)[0]\n",
    "\n",
    "# selecting S in year 1 where S (ITM) > K\n",
    "S_1y = paths[1][ind_itm_1y]\n",
    "\n",
    "# selecting exercise values in year 1\n",
    "exercise_V_1y = S_1y - K\n",
    "\n",
    "# discounting to year 1 the cash flows of year 2 where K > S and the cash flows of year 3 where K > S\n",
    "disc_V_1y =  np.maximum(V[2][ind_itm_1y]*dfs[2][ind_itm_1y],\n",
    "                        V[3][ind_itm_1y]*dfs[2][ind_itm_1y]*dfs[3][ind_itm_1y],\n",
    "                        V[4][ind_itm_1y]*dfs[2][ind_itm_1y]*dfs[3][ind_itm_1y]*dfs[4][ind_itm_1y])\n",
    "\n",
    "# obtaining values of continuing in year 2\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(S_1y.reshape(-1, 1))  \n",
    "S_1y_scld = scaler.transform(S_1y.reshape(-1, 1))\n",
    "#mlp.fit(S_1y_scld.reshape(-1, 1), disc_V_1y)\n",
    "continuation_V_1y = fitted1.predict(S_1y_scld.reshape(-1, 1))\n",
    "\n",
    "# selecting indices of original paths where exercise_V_1y > continuation_V_1y\n",
    "ind_1y = np.take(ind_itm_1y, np.where(exercise_V_1y > continuation_V_1y))[0]\n",
    "\n",
    "# inserting exercise values in cash flows in year 1 where exercise_V_1y > continuation_V_1y\n",
    "V[1][ind_1y] = exercise_V_1y[np.where(exercise_V_1y > continuation_V_1y)]\n",
    "\n",
    "# inserting zero values in cash flows in year 2 and year 3 where exercise_V_1y > continuation_V_1y\n",
    "V[2][ind_1y], V[3][ind_1y], V[4][ind_1y] = 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of call options: 500,000 \n",
      "\n",
      "t = 4: % ITM call options = 19.72% \n",
      "t = 4: % OTM call options = 80.28% \n",
      "\n",
      "t = 3: % ITM call options = 106.14% \n",
      "t = 3: % OTM call options = 93.86% \n",
      "\n",
      "t = 2: % ITM call options = 10.07% \n",
      "t = 2: % OTM call options = 79.85% \n",
      "\n",
      "t = 1: % ITM call options = 7.11% \n",
      "t = 1: % OTM call options = 85.77%\n"
     ]
    }
   ],
   "source": [
    "print(f'# of call options: {a:,.0f} \\n\\n' \\\n",
    "      f't = 4: % ITM call options = {(a-V[4][V[4]==0].shape[0])/a*100:,.2f}% \\n' \\\n",
    "      f't = 4: % OTM call options = {V[4][V[4]==0].shape[0]/a*100:,.2f}% \\n\\n' \\\n",
    "      f't = 3: % ITM call options = {(n-V[3][V[3]==0].shape[0])/a*100:,.2f}% \\n' \\\n",
    "      f't = 3: % OTM call options = {V[3][V[3]==0].shape[0]/a*100:,.2f}% \\n\\n' \\\n",
    "      f't = 2: % ITM call options = {(a-V[2][V[2]==0].shape[0])/n*100:,.2f}% \\n' \\\n",
    "      f't = 2: % OTM call options = {V[2][V[2]==0].shape[0]/a*100:,.2f}% \\n\\n' \\\n",
    "      f't = 1: % ITM call options = {(a-V[1][V[1]==0].shape[0])/n*100:,.2f}% \\n' \\\n",
    "      f't = 1: % OTM call options = {V[1][V[1]==0].shape[0]/a*100:,.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discounting values to year 0\n",
    "dfs_cum = np.array([np.cumprod(i) for i in dfs[1:].T]).T\n",
    "disc_V = V.copy()*dfs_cum\n",
    "\n",
    "# calculating the price and standard error\n",
    "c = np.sum([max(i) for i in disc_V.T])/a\n",
    "c2 = np.sum([max(i)**2 for i in disc_V.T])/a\n",
    "std_err = np.sqrt((c2-c**2)/a)\n",
    "call_bond = bond(0,curve0)-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bermudan call option price is: 0.9816311071. The standard error is: 0.0016220807. \n",
      "The bond price at t=0: 101.1849579254. The callable bond price at t=0: 100.2033268183.\n"
     ]
    }
   ],
   "source": [
    "print(f'The Bermudan call option price is: {c:.10f}. The standard error is: {std_err:.10f}. \\n' \\\n",
    "      f'The bond price at t=0: {bond(0,curve0):.10f}. The callable bond price at t=0: {call_bond:.10f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "oos = [max(i) for i in disc_V.T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=59.21213261942166, pvalue=0.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(ins,oos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
